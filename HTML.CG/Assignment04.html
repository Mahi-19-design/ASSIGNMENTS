<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
<h1> The History of Computers and the Internet</h1>
<blockquote><b><i>“The history of computers is the story of humanity’s quest to make thinking machines that extend the power of the human mind.”</i></b></blockquote>
<h2> Early Computers</h2>
<p> The history of the computer began with simple manual calculating devices like the Abacus (c. 2600 BCE) and evolved through mechanical calculators like <i>Pascal's Pascaline </i>(1642) and <i> Leibniz's Stepped Reckoner </i>(1673). A key conceptual leap came with <i>Charles Babbage's </i>design for the<u><b>Analytical Engine</b></u> in the 19th century, which featured a programmable concept and punched cards. The first large-scale electronic digital computers, such as <mark><strong><abbr title="Electronic Numerical Integrator And Computer" >ENIAC</abbr></strong></mark>, were built in the 1940s, leading to the commercialization of computers with <mark><strong><abbr title="Universal Automatic Computer">UNIVAC</abbr> </strong></mark> in 1951 and the <i>microchip revolution</i> in the 1970s. These early developments introduced ideas of memory, processing, and programmability, which became the foundation of modern computers. Although they were slow and mechanical, early computers marked the beginning of the computing revolution.</p>
<h2> Electromechanical Computers</h2>
<p> <mark> <b>Electromechanical Computers</b></mark> were an important step between <b>mechanical calculators</b> and<b> fully electronic computers</b>. They used <i>electrical switches</i> and <i>mechanical</i> parts together, making them<del> faster</del> and more reliable than purely mechanical devices.<i> Herman Hollerith’s </i>punched card machines, used for the 1890 U.S. Census, are early examples. Later, <i>Konrad Zuse’s Z3</i> (1941) became the first programmable electromechanical computer. These machines laid the foundation for modern computing by introducing<u> programmability</u> and <u> automation </u>.These systems introduced the use of binary arithmetic and programmability, which greatly influenced future designs. Although bulky and slow compared to later models, they played a key role in wartime code-breaking and scientific calculations. Electromechanical computers paved the way for fully electronic, high-speed computers of the first generation.</p>
<h2> Mathematics in Computing </h2>
<p> A famous equation: E=mc<sup>2</sup>.</p>
<p> Another example: H<sub>2</sub>O</p>
<h2>Generations of Computers </h2>
<p>The history of computers is often divided into different generations based on the technology used. The <b><mark>First Generation </mark></b>(1940s–1950s) used vacuum tubes, were very large, and worked on machine language; examples include<b> ENIAC</b> and<b> UNIVAC </b>. The <b><mark>Second Generation</mark></b> (1950s–1960s) replaced vacuum tubes with transistors, making computers smaller, faster, and more reliable, and introduced high-level languages like <b>FORTRAN</b> and<b>COBOL</b>. In the<b><mark> Third Generation </mark></b>(1960s–1970s), integrated circuits (ICs) were introduced, which allowed more powerful and cheaper machines. The <b><mark>Fourth Generation</mark></b> (1970s–1990s) saw the invention of microprocessors, leading to the rise of personal computers from companies like Apple and IBM. Finally, the<b><mark> Fifth Generation</mark></b> (1990s–Present) focuses on <i>artificial intelligence </i>,<i> robotics</i>, and <i>advanced computing technologies </i>. Each generation made computers faster, smaller, more efficient, and easier to use, shaping the digital world we live in today. </p>
<h2> Modern Era </h2>
<p>The modern era of computers began in the 1990s and continues today, marked by rapid advancements in <i>speed </i>,<i>storage </i>, and<i>connectivity </i>. The invention of the <mark><b>Internet</b></mark> and the <mark><b>World Wide Web </b> </mark>transformed how people communicate, work, and access information. Personal computers became common, followed by the rise of laptops, smartphones, and tablets. Cloud computing, social media, and big data further revolutionized technology use. Today,<i> artificial intelligence, machine learning,</i> and<i>quantum computing</i> are shaping the future of the digital world.Personal computers became widely available, followed by the rise of laptops, tablets, and smartphones, making computing portable and accessible to everyone.Recent advancements such as quantum computing, virtual reality, and robotics show the direction of future innovation. The modern era is defined by constant upgrades and the increasing role of computers in every aspect of human life.</p>
</body>
</html>